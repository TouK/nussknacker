package pl.touk.nussknacker.engine.kafka.source

import pl.touk.nussknacker.engine.flink.api.timestampwatermark.TimestampWatermarkHandler
import org.apache.flink.types.Nothing
import org.apache.kafka.clients.consumer.ConsumerRecord
import pl.touk.nussknacker.engine.api.context.{ProcessCompilationError, ValidationContext}
import pl.touk.nussknacker.engine.api.context.transformation.{NodeDependencyValue, SingleInputGenericNodeTransformation}
import pl.touk.nussknacker.engine.api.definition.{DualParameterEditor, NodeDependency, Parameter, StringParameterEditor}
import pl.touk.nussknacker.engine.api.editor.DualEditorMode
import pl.touk.nussknacker.engine.api.process.ProcessObjectDependencies
import pl.touk.nussknacker.engine.flink.api.process.{FlinkContextInitializer, FlinkSource}
import pl.touk.nussknacker.engine.kafka.{KafkaConfig, KafkaUtils, RecordFormatter}
import pl.touk.nussknacker.engine.kafka.serialization.KafkaDeserializationSchemaFactory

import scala.reflect.ClassTag


/**
  * Base factory for Kafka sources with additional metadata variable.
  * It is based on [[pl.touk.nussknacker.engine.api.context.transformation.SingleInputGenericNodeTransformation]]
  * that allows custom ValidationContext and Context transformations, which are provided by [[pl.touk.nussknacker.engine.kafka.source.KafkaGenericContextInitializer]]
  *
  * @param deserializationSchemaFactory - produces KafkaDeserializationSchema for [[pl.touk.nussknacker.engine.kafka.source.KafkaSource]]
  * @param timestampAssigner            - provides timestampAsigner and WatermarkStrategy to KafkaSource
  * @param formatter                    - support for test data parser and generator
  * @param processObjectDependencies
  * @tparam K - type of key of kafka event that is generated by raw source (SourceFunction).
  * @tparam V - type of value of kafka event that is generated by raw source (SourceFunction).
  */
class KafkaGenericNodeSourceFactory[K: ClassTag, V: ClassTag](deserializationSchemaFactory: KafkaDeserializationSchemaFactory[ConsumerRecord[K, V]],
                                                              timestampAssigner: Option[TimestampWatermarkHandler[ConsumerRecord[K, V]]],
                                                              formatter: RecordFormatter,
                                                              processObjectDependencies: ProcessObjectDependencies)
  extends BaseKafkaSourceFactory[ConsumerRecord[K, V]](deserializationSchemaFactory, timestampAssigner, formatter, processObjectDependencies)
    with SingleInputGenericNodeTransformation[FlinkSource[ConsumerRecord[K, V]]] {

  protected val customContextInitializer: KafkaGenericContextInitializer[K, V, DefinedParameter, State] = new KafkaGenericContextInitializer[K, V, DefinedParameter, State]

  override type State = Nothing

  override def initialParameters: List[Parameter] = Parameter[String](KafkaGenericNodeSourceFactory.TopicParamName)
    .copy(editor = Some(DualParameterEditor(
      simpleEditor = StringParameterEditor,
      defaultMode = DualEditorMode.RAW))
    ) :: Nil

  override def contextTransformation(context: ValidationContext, dependencies: List[NodeDependencyValue])(implicit nodeId: ProcessCompilationError.NodeId)
  : NodeTransformationDefinition = {
    case TransformationStep(Nil, _) => NextParameters(initialParameters)
    case step@TransformationStep((KafkaGenericNodeSourceFactory.TopicParamName, _) :: Nil, None) =>
      FinalResults(customContextInitializer.validationContext(context, dependencies, step.parameters, step.state))
  }

  override def implementation(params: Map[String, Any], dependencies: List[NodeDependencyValue], finalState: Option[Nothing]): FlinkSource[ConsumerRecord[K, V]] = {
    val topic = params(KafkaGenericNodeSourceFactory.TopicParamName).asInstanceOf[String]
    val kafkaConfig = KafkaConfig.parseProcessObjectDependencies(processObjectDependencies)
    createSource(List(topic), kafkaConfig)
  }

  override protected def createSource(topics: List[String], kafkaConfig: KafkaConfig): KafkaSource[ConsumerRecord[K, V]] = {
    val preparedTopics = topics.map(KafkaUtils.prepareKafkaTopic(_, processObjectDependencies))
    val deserializationSchema = deserializationSchemaFactory.create(topics, kafkaConfig)
    new KafkaSource[ConsumerRecord[K, V]](preparedTopics, kafkaConfig, deserializationSchema, timestampAssigner, formatter) {
      override val contextInitializer: FlinkContextInitializer[ConsumerRecord[K, V]] = customContextInitializer
    }
  }

  override def nodeDependencies: List[NodeDependency] = Nil
}

object KafkaGenericNodeSourceFactory {
  final val TopicParamName = "Topic"
}

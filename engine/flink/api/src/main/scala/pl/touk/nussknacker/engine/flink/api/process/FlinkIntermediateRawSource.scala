package pl.touk.nussknacker.engine.flink.api.process

import org.apache.flink.api.common.functions.MapFunction
import org.apache.flink.api.common.typeinfo.TypeInformation
import org.apache.flink.streaming.api.TimeCharacteristic
import org.apache.flink.streaming.api.functions.source.SourceFunction
import org.apache.flink.streaming.api.scala.{DataStream, StreamExecutionEnvironment}
import pl.touk.nussknacker.engine.api.Context
import pl.touk.nussknacker.engine.api.context.ProcessCompilationError.NodeId
import pl.touk.nussknacker.engine.api.context.ValidationContext
import pl.touk.nussknacker.engine.api.process.Source
import pl.touk.nussknacker.engine.api.typed.typing
import pl.touk.nussknacker.engine.flink.api.compat.ExplicitUidInOperatorsSupport
import pl.touk.nussknacker.engine.flink.api.timestampwatermark.TimestampWatermarkHandler


/**
  * Source with typical source stream trasformations:
  *  1. adds source using provided SourceFunction (here raw source produces raw data)
  *  2. sets UID
  *  3. assigns timestamp and watermarks
  *  4. initializes Context that is streamed within output DataStream (here raw data are mapped to Context)
  * It separates raw event data produced by SourceFunction and data released to the stream as Context variables.
  * By default it uses basic implementation of initializer, see [[BasicFlinkContextInitializer]].
  *
  * @tparam Raw - type of raw event that is generated by flink source function.
  */
trait FlinkIntermediateRawSource[Raw] extends ExplicitUidInOperatorsSupport { self: Source[Raw] =>

  // We abstracting to stream so theoretically it shouldn't be defined on this level but:
  // * for test mechanism purpose we need to know what type will be generated.
  // * for production sources (eg BaseFlinkSource, KafkaSource) it is used to determine type information for flinkSourceFunction
  def typeInformation: TypeInformation[Raw]

  def timestampAssigner : Option[TimestampWatermarkHandler[Raw]]

  val contextInitializer: FlinkContextInitializer[Raw] = new BasicFlinkContextInitializer[Raw]

  def prepareSourceStream(env: StreamExecutionEnvironment, flinkNodeContext: FlinkCustomNodeContext, sourceFunction: SourceFunction[Raw]): DataStream[Context] = {
    env.setStreamTimeCharacteristic(if (timestampAssigner.isDefined) TimeCharacteristic.EventTime else TimeCharacteristic.IngestionTime)

    //1. add source and 2. set UID
    val rawSourceWithUid = setUidToNodeIdIfNeed(flinkNodeContext, env
      .addSource[Raw](sourceFunction)(typeInformation)
      .name(s"${flinkNodeContext.metaData.id}-${flinkNodeContext.nodeId}-source"))

    //3. assign timestamp and watermark policy
    val rawSourceWithUidAndTimestamp = timestampAssigner
      .map(_.assignTimestampAndWatermarks(rawSourceWithUid))
      .getOrElse(rawSourceWithUid)

    //4. initialize Context and spool Context to the stream
    val typeInformationFromNodeContext = flinkNodeContext.typeInformationDetection.forContext(flinkNodeContext.validationContext.left.get)
    rawSourceWithUidAndTimestamp
      .map(contextInitializer.initContext(flinkNodeContext.metaData.id, flinkNodeContext.nodeId))(typeInformationFromNodeContext)
  }
}

/**
  * FlinkContextInitializer provides definition of Context returned within DataStream by FlinkSource
  * and map function that transforms raw event to Context.
  *
  * @tparam Raw - type of raw event that is generated by flink source function.
  */
abstract class FlinkContextInitializer[Raw] extends Serializable {

  /**
    *
    * @param context - ValidationContext initialized with global variables, definition of variables available in `Context` scope and their types
    * @param outputVariableName - default name of the main output variable
    * @param outputVariableType - type of the main output variable
    */
  def validationContext(context: ValidationContext, outputVariableName: String, outputVariableType: typing.TypingResult)(implicit nodeId: NodeId): ValidationContext

  /**
    * Initializes `Context` with raw event value.
    *
    * @param processId - id of the process or flink job, used to setup name of created Context
    * @param taskName - name of the task within the process or flink job, used to setup name of created Context
    */
  def initContext(processId: String, taskName: String): MapFunction[Raw, Context]
}
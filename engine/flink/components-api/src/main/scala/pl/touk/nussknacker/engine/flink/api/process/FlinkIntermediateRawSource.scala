package pl.touk.nussknacker.engine.flink.api.process

import com.github.ghik.silencer.silent
import org.apache.flink.api.common.functions.{RichMapFunction, RuntimeContext}
import org.apache.flink.api.common.typeinfo.TypeInformation
import org.apache.flink.configuration.Configuration
import org.apache.flink.streaming.api.datastream.{DataStream, DataStreamSource}
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment
import org.apache.flink.streaming.api.functions.source.SourceFunction
import pl.touk.nussknacker.engine.api.Context
import pl.touk.nussknacker.engine.api.process.{
  BasicContextInitializer,
  ContextInitializer,
  ContextInitializingFunction,
  Source
}
import pl.touk.nussknacker.engine.api.runtimecontext.EngineRuntimeContext
import pl.touk.nussknacker.engine.api.typed.typing.Unknown
import pl.touk.nussknacker.engine.flink.api.compat.ExplicitUidInOperatorsSupport
import pl.touk.nussknacker.engine.flink.api.timestampwatermark.TimestampWatermarkHandler

/**
  * Source with typical source stream transformations:
  *  1. adds source using provided SourceFunction (here raw source produces raw data)
  *  2. sets UID
  *  3. assigns timestamp and watermarks
  *  4. initializes Context that is streamed within output DataStream (here raw data are mapped to Context)
  * It separates raw event data produced by SourceFunction and data released to the stream as Context variables.
  * By default it uses basic "single input value" implementation of initializer, see [[BasicContextInitializer]].
  *
  * @tparam Raw - type of raw event that is generated by flink source function.
  */
trait FlinkIntermediateRawSource[Raw] extends CustomContextInitializerSource[Raw] { self: Source =>

  // We abstracting to stream so theoretically it shouldn't be defined on this level but:
  // * for test mechanism purpose we need to know what type will be generated.
  // * for production sources (eg BaseFlinkSource, KafkaSource) it is used to determine type information for flinkSourceFunction
  def typeInformation: TypeInformation[Raw]

  def timestampAssigner: Option[TimestampWatermarkHandler[Raw]]

  override val contextInitializer: ContextInitializer[Raw] = FlinkIntermediateRawSourceUtils.defaultContextInitializer

  @silent("deprecated")
  def prepareSourceStream(
      env: StreamExecutionEnvironment,
      flinkNodeContext: FlinkCustomNodeContext,
      sourceFunction: SourceFunction[Raw]
  ): DataStream[Context] = {
    val source = FlinkIntermediateRawSourceUtils.createSource(env, sourceFunction, typeInformation)
    FlinkIntermediateRawSourceUtils.prepareSource(source, flinkNodeContext, timestampAssigner, Some(contextInitializer))
  }

}

trait CustomContextInitializerSource[T] { self: Source =>
  def contextInitializer: ContextInitializer[T]
}

object FlinkIntermediateRawSourceUtils extends ExplicitUidInOperatorsSupport {

  def defaultContextInitializer[Raw] = new BasicContextInitializer[Raw](Unknown)

  @silent("deprecated")
  def createSource[Raw](
      env: StreamExecutionEnvironment,
      sourceFunction: SourceFunction[Raw],
      typeInformation: TypeInformation[Raw]
  ): DataStreamSource[Raw] = {
    env.addSource[Raw](sourceFunction, typeInformation)
  }

  def prepareSource[Raw](
      source: DataStreamSource[Raw],
      flinkNodeContext: FlinkCustomNodeContext,
      timestampAssigner: Option[TimestampWatermarkHandler[Raw]] = None,
      customContextInitializer: Option[ContextInitializer[Raw]] = None,
  ): DataStream[Context] = {

    // 1. set UID
    val rawSourceWithUid = setUidToNodeIdIfNeed[Raw](
      flinkNodeContext,
      source
        .name(flinkNodeContext.nodeId)
    )

    // 2. assign timestamp and watermark policy
    val rawSourceWithUidAndTimestamp = timestampAssigner
      .map(_.assignTimestampAndWatermarks(rawSourceWithUid))
      .getOrElse(rawSourceWithUid)

    // 3. initialize Context and spool Context to the stream
    rawSourceWithUidAndTimestamp
      .map(
        new FlinkContextInitializingFunction(
          customContextInitializer.getOrElse(defaultContextInitializer),
          flinkNodeContext.nodeId,
          flinkNodeContext.convertToEngineRuntimeContext
        ),
        flinkNodeContext.contextTypeInfo
      )
  }

}

class FlinkContextInitializingFunction[Raw](
    contextInitializer: ContextInitializer[Raw],
    nodeId: String,
    convertToEngineRuntimeContext: RuntimeContext => EngineRuntimeContext
) extends RichMapFunction[Raw, Context] {

  private var initializingStrategy: ContextInitializingFunction[Raw] = _

  override def open(parameters: Configuration): Unit = {
    val contextIdGenerator = convertToEngineRuntimeContext(getRuntimeContext).contextIdGenerator(nodeId)
    initializingStrategy = contextInitializer.initContext(contextIdGenerator)
  }

  override def map(input: Raw): Context = {
    initializingStrategy(input)
  }

}

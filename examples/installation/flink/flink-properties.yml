taskmanager.numberOfTaskSlots: 8
# Nu requires a little bit more metaspace than Flink default allocate based on process size
taskmanager.memory.process.size: 1500m
taskmanager.memory.jvm-metaspace.size: 400m

state.backend.type: filesystem
state.checkpoints.dir: file:///opt/flink/data/checkpoints
state.savepoints.dir: file:///opt/flink/data/savepoints

#Below are base settings for rocksdb metrics, that can be used for grafana dashboards
state.backend.rocksdb.metrics.estimate-num-keys: true
state.backend.rocksdb.metrics.estimate-live-data-size: true
state.backend.rocksdb.metrics.cur-size-all-mem-tables: true
state.backend.rocksdb.metrics.size-all-mem-tables: true
# We can have many jobs per cluster, in such setting managed memory is not easy to tune
state.backend.rocksdb.memory.managed: false
# For frequent writes increase the value as needed. Currently RocksDB settings can only be changed per Flink cluster
state.backend.rocksdb.writebuffer.size: 256m

metrics.reporters: influxdb_reporter
metrics.reporter.influxdb_reporter.factory.class: org.apache.flink.metrics.influxdb.InfluxdbReporterFactory
metrics.reporter.influxdb_reporter.host: telegraf
metrics.reporter.influxdb_reporter.port: 8087
metrics.reporter.influxdb_reporter.db: nussknacker_metrics
metrics.reporter.influxdb_reporter.scope.variables.excludes: tm_id;job_id;task_id;task_attempt_id;operator_id;task_attempt_num;task_name
metrics.scope.jm: local.<host>.jobmanagerGlobal
metrics.scope.jm-job: local.<host>.jobmanagerJob.<job_name>
metrics.scope.tm: local.<host>.taskmanagerGlobal.<tm_id>
metrics.scope.tm-job: local.<host>.taskmanagerJob.<tm_id>.<job_name>
metrics.scope.task: local.<host>.taskmanagerTask.<tm_id>.<job_name>.<task_name>.<subtask_index>
metrics.scope.operator: local.<host>.taskmanagerTask.<tm_id>.<job_name>.<operator_name>.<subtask_index>
